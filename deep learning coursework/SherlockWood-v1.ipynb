{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook page, the two models would be trained and be used to predict pictures.\n",
    "In the Following parts, the two models, loss and accuracy curves, consusion matrix and interperting using captum would be shown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary packages\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "import os\n",
    "from torch.utils.data import random_split\n",
    "import torchvision\n",
    "from ray import tune\n",
    "from ray.tune import CLIReporter\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from PIL import Image"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare work before training the model\n",
    "\n",
    "1. show the number of dataset for trainin and testing. Such function is shown below. By doin this parts, users could see clearly how the dataset consists of and could use this when doing further analyse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_number():\n",
    "    picture_frames = pd.read_csv('/kaggle/input/deep-learning-for-msc-2022-23/train.csv')\n",
    "    labels = picture_frames.iloc[:,1]\n",
    "    labels = labels.to_list()\n",
    "    x = set(labels)\n",
    "    y = []\n",
    "    for a in x:\n",
    "        y.append(labels.count(a))\n",
    "    x = list(x)\n",
    "    plt.figure(figsize=(5, 4))\n",
    "    plt.bar(x, y, facecolor='#1f77b4', edgecolor='k')\n",
    "    # plt.xticks(rotation=90)\n",
    "    plt.tick_params(labelsize=15)\n",
    "    plt.xlabel('class', fontsize=10)\n",
    "    plt.ylabel('number of data', fontsize=10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. create the dataset class to load the pictures in to RAM and change picture file into tensor. A parameter is added as it could create training\n",
    "dataset and test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CellPictureDataset(Dataset):\n",
    "\n",
    "    def __init__(self, root_dir, csv_file=None, transform=None, test=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        if csv_file is not None:\n",
    "            self.data_frame = pd.read_csv(csv_file)\n",
    "        self.root_dir = os.path.abspath(root_dir)\n",
    "        self.transform = transform\n",
    "        self.test = test\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(os.listdir(self.root_dir))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        if self.test is False:\n",
    "            img_name = os.path.join(self.root_dir,\n",
    "                                    self.data_frame.iloc[idx, 0])\n",
    "        else:\n",
    "            img_name = os.path.join(self.root_dir, os.listdir(self.root_dir)[idx])\n",
    "        image = Image.open(img_name)\n",
    "        if self.transform:\n",
    "            self.image = self.transform(image)\n",
    "        if self.test is False:\n",
    "            label = self.data_frame.iloc[idx, 1]\n",
    "            return self.image, label\n",
    "        else:\n",
    "            return self.image"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. design my own convnet. I generate it as a 4-layer convnet, and set the last one layer as a hyperparameter for further modifying."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "class MyConvNet(nn.Module):\n",
    "    def __init__(self, l1=120):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(collections.OrderedDict([\n",
    "            ('conv1', nn.Conv2d(3,32,5,stride=5)),\n",
    "            ('relu1', nn.ReLU()),\n",
    "            ('conv2', nn.Conv2d(32,16,5,stride=2)),\n",
    "            ('relu2', nn.ReLU()),\n",
    "            # Put in a linear layers ...\n",
    "            ('flatten', nn.Flatten()),                                          \n",
    "            ('fc1', nn.Linear(80*80,l1)),\n",
    "            ('relu3', nn.ReLU()),\n",
    "            ('fc3', nn.Linear(l1,4)),\n",
    "        ]))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. visualize a batch. Before using the dataset to train the model, it is necessary to deal with the pictures. For example, it is a good way to \n",
    "reshaple the pictures into a same shape, which could improve the robustness of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "\n",
    "def show_a_batch():\n",
    "\n",
    "    train_transform = transforms.Compose([transforms.RandomResizedCrop(224),\n",
    "                                          transforms.RandomHorizontalFlip(),\n",
    "                                          transforms.ToTensor(),\n",
    "                                          transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "                                         ])\n",
    "    train_dataset = CellPictureDataset('/kaggle/input/deep-learning-for-msc-2022-23/train', csv_file='/kaggle/input/deep-learning-for-msc-2022-23/train.csv', transform=train_transform)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, num_workers=0)\n",
    "\n",
    "    images, labels = next(iter(train_loader))\n",
    "\n",
    "    images = images.numpy()\n",
    "\n",
    "    n=6\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    grid = ImageGrid(fig, 111,  # 类似绘制子图 subplot(111)\n",
    "                    nrows_ncols=(n, n),  # 创建 n 行 m 列的 axes 网格\n",
    "                    axes_pad=0.02,  # 网格间距\n",
    "                    share_all=True\n",
    "                    )\n",
    "\n",
    "    # 遍历每张图像\n",
    "    for ax, im in zip(grid, images):\n",
    "        ax.imshow(im.transpose((1,2,0)))\n",
    "        ax.axis('off')\n",
    "\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using ray tune to modyfy hyperparameters\n",
    "\n",
    "In this parts, the functions are used to modify the hyperparameters of the model. The benefits of modify such hyperparameters are, for example, \n",
    "preventing overfitting during training and, improve accuracy of the model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. training function for model_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the function for trianing model_1, in this function, set number of last connection layer nurons, learnin rate, monmentum, batch size as hyperparameter\n",
    "def train_cifar(config, checkpoint_dir=None, data_dir=None):\n",
    "    net = MyConvNet(config[\"l1\"])\n",
    "    device = \"cpu\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda:0\"\n",
    "        if torch.cuda.device_count() > 1:\n",
    "            net = nn.DataParallel(net)\n",
    "    net.to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(net.parameters(), lr=config[\"lr\"], momentum=config[\"momentum\"])\n",
    "\n",
    "    csv_dir = \"/kaggle/input/deep-learning-for-msc-2022-23/train.csv\"\n",
    "    train_transform = transforms.Compose([transforms.RandomResizedCrop(224),\n",
    "                                      transforms.RandomHorizontalFlip(),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "                                     ])\n",
    "    train_dir = \"/kaggle/input/deep-learning-for-msc-2022-23/train\"\n",
    "    trainset = CellPictureDataset(train_dir, csv_file=csv_dir, transform=train_transform)\n",
    "\n",
    "    test_abs = int(len(trainset) * 0.8)\n",
    "    train_subset, val_subset = random_split(\n",
    "        trainset, [test_abs, len(trainset) - test_abs])\n",
    "\n",
    "    trainloader =DataLoader(\n",
    "        train_subset,\n",
    "        batch_size=int(config[\"batch_size\"]),\n",
    "        shuffle=True,\n",
    "        num_workers=2,\n",
    "        pin_memory=True)\n",
    "    valloader = DataLoader(\n",
    "        val_subset,\n",
    "        batch_size=int(config[\"batch_size\"]),\n",
    "        shuffle=True,\n",
    "        num_workers=2,\n",
    "        pin_memory=True)\n",
    "\n",
    "    for epoch in range(35):  # loop over the dataset multiple times\n",
    "        running_loss = 0.0\n",
    "        epoch_steps = 0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            net.train()\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            epoch_steps += 1\n",
    "#             print(outputs.device)\n",
    "            # if i % 100 == 99:  # print every 2000 mini-batches\n",
    "            #     print(\"[%d, %5d] loss: %.3f\" % (epoch + 1, i + 1,\n",
    "            #                                     running_loss / epoch_steps))\n",
    "            #     running_loss = 0.0\n",
    "\n",
    "        # Validation loss\n",
    "        val_loss = 0.0\n",
    "        val_steps = 0\n",
    "        total = 0\n",
    "        correct = 0\n",
    "        for i, data in enumerate(valloader, 0):\n",
    "            with torch.no_grad():\n",
    "#                 net.eval()\n",
    "                inputs, labels = data\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                outputs = net(inputs)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.cpu().numpy()\n",
    "                val_steps += 1\n",
    "\n",
    "        tune.report(loss=(val_loss / val_steps), accuracy=correct / total)\n",
    "#     print(\"Finished Training\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. training function for model_2. The used model is resnet18, which is the best choice from resnet50, vgg16, etc. Through testing, a complex model may be not suitable for this dataset. When used vgg16, the loss is even higher than model_1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # the function for trianing model_2, in this function, set learnin rate, monmentum as hyperparameter\n",
    "def train_cifar_2(config, checkpoint_dir=None, data_dir=None):\n",
    "    net = torchvision.models.resnet18()\n",
    "    net.fc = nn.Linear(net.fc.in_features, 4)\n",
    "    device = \"cpu\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda:0\"\n",
    "        if torch.cuda.device_count() > 1:\n",
    "            net = nn.DataParallel(net)\n",
    "    net.to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(net.parameters(), lr=config[\"lr\"], momentum=config[\"momentum\"])\n",
    "\n",
    "    if checkpoint_dir:\n",
    "        model_state, optimizer_state = torch.load(\n",
    "            os.path.join(checkpoint_dir, \"checkpoint\"))\n",
    "        net.load_state_dict(model_state)\n",
    "        optimizer.load_state_dict(optimizer_state)\n",
    "\n",
    "    csv_dir = \"/kaggle/input/deep-learning-for-msc-2022-23/train.csv\"\n",
    "    train_transform = transforms.Compose([transforms.RandomResizedCrop(224),\n",
    "                                      transforms.RandomHorizontalFlip(),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "                                     ])\n",
    "    train_dir = \"/kaggle/input/deep-learning-for-msc-2022-23/train\"\n",
    "    trainset = CellPictureDataset(train_dir, csv_file=csv_dir, transform=train_transform)\n",
    "\n",
    "    test_abs = int(len(trainset) * 0.8)\n",
    "    train_subset, val_subset = random_split(\n",
    "        trainset, [test_abs, len(trainset) - test_abs])\n",
    "\n",
    "    trainloader =DataLoader(\n",
    "        train_subset,\n",
    "        batch_size=int(config[\"batch_size\"]),\n",
    "        shuffle=True,\n",
    "        num_workers=2,\n",
    "        pin_memory=True)\n",
    "    valloader = DataLoader(\n",
    "        val_subset,\n",
    "        batch_size=int(config[\"batch_size\"]),\n",
    "        shuffle=True,\n",
    "        num_workers=2,\n",
    "        pin_memory=True)\n",
    "\n",
    "    for epoch in range(35):  # loop over the dataset multiple times\n",
    "        running_loss = 0.0\n",
    "        epoch_steps = 0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            net.train()\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            epoch_steps += 1\n",
    "#             print(outputs.device)\n",
    "            # if i % 100 == 99:  # print every 2000 mini-batches\n",
    "            #     print(\"[%d, %5d] loss: %.3f\" % (epoch + 1, i + 1,\n",
    "            #                                     running_loss / epoch_steps))\n",
    "            #     running_loss = 0.0\n",
    "\n",
    "        # Validation loss\n",
    "        val_loss = 0.0\n",
    "        val_steps = 0\n",
    "        total = 0\n",
    "        correct = 0\n",
    "        for i, data in enumerate(valloader, 0):\n",
    "            with torch.no_grad():\n",
    "#                 net.eval()\n",
    "                inputs, labels = data\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                outputs = net(inputs)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.cpu().numpy()\n",
    "                val_steps += 1\n",
    "\n",
    "#         with tune.checkpoint_dir(epoch) as checkpoint_dir:\n",
    "#             path = os.path.join(checkpoint_dir, \"checkpoint\")\n",
    "#             torch.save((net.state_dict(), optimizer.state_dict()), path)\n",
    "\n",
    "        tune.report(loss=(val_loss / val_steps), accuracy=correct / total)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. function for testing accuracy. It is necessary to split the training dataset as training parts and validation parts, which could test whether the model is overfitting or not. If plot the loss or accuracy curves, it can be seen that if as epoch iterating, the loss graudally decrease and accuracy increase, the model is heathy. If, for example, the training accuracy gradually increase, and even becomes nearly 100%, but the validation accuracy increase firstly and then decrease, it shows the model is overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_accuracy(net, device=\"cpu\"):\n",
    "    root_dir = \"D://python_code//deep learning coursework//train\"\n",
    "    csv_dir = \"D://python_code//deep learning coursework//train.csv\"\n",
    "    data_transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize([0.5,0.5,0.5],[0.5,0.5,0.5])])\n",
    "    trainset = CellPictureDataset(root_dir=root_dir, csv_file=csv_dir, transform=data_transform)\n",
    "    testloader = DataLoader(trainset, batch_size=4, shuffle=True, num_workers=2)\n",
    "    \n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    return correct / total"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. using tune from ray to select the best model. Tune from is a package for modifying hyperparameters, it randomly set the hyperparameter from 'config', then doing the above functions. In this part, the complicated process would be omitted, as it is hard to show all the process in a notebook. Interval form the best model I have tried would be shown as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the interval for model_1 is in this function\n",
    "def main_1(num_samples=10, max_num_epochs=10, gpus_per_trial=2):\n",
    "    # train_dir = os.path.abspath(\"train\")\n",
    "    # load_data(train_dir)\n",
    "    configs = {\n",
    "#         \"l1\": tune.sample_from(lambda _: 2 ** np.random.randint(8, 10)),\n",
    "        \"l1\": 256,\n",
    "        \"lr\": tune.loguniform(0.00883, 0.00885),\n",
    "#         \"lr\": 0.00105,\n",
    "#         \"batch_size\": tune.choice([16, 32]),\n",
    "        \"batch_size\": 16,\n",
    "        \"momentum\": tune.loguniform(0.65, 0.68)\n",
    "#         \"momentum\": 0.7\n",
    "    }\n",
    "    scheduler = ASHAScheduler(\n",
    "        metric=\"loss\",\n",
    "        mode=\"min\",\n",
    "        max_t=max_num_epochs,\n",
    "        grace_period=1,\n",
    "        reduction_factor=2)\n",
    "    reporter = CLIReporter(\n",
    "        # parameter_columns=[\"l1\", \"l2\", \"lr\", \"batch_size\"],\n",
    "        metric_columns=[\"loss\", \"accuracy\", \"training_iteration\"])\n",
    "    result = tune.run(\n",
    "        train_cifar,\n",
    "        resources_per_trial={\"cpu\": 2, \"gpu\": gpus_per_trial},\n",
    "        config=configs,\n",
    "        num_samples=num_samples,\n",
    "        scheduler=scheduler)\n",
    "#         progress_reporter=reporter)\n",
    "\n",
    "    best_trial = result.get_best_trial(\"loss\", \"min\", \"last\")\n",
    "    print(\"Best trial config: {}\".format(best_trial.config))\n",
    "    print(\"Best trial final validation loss: {}\".format(\n",
    "        best_trial.last_result[\"loss\"]))\n",
    "    print(\"Best trial final validation accuracy: {}\".format(\n",
    "        best_trial.last_result[\"accuracy\"]))\n",
    "\n",
    "    best_trained_model = MyConvNet(best_trial.config[\"l1\"])\n",
    "    device = \"cpu\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda:0\"\n",
    "        if gpus_per_trial > 1:\n",
    "            best_trained_model = nn.DataParallel(best_trained_model)\n",
    "    best_trained_model.to(device)\n",
    "\n",
    "#     best_checkpoint_dir = best_trial.checkpoint.dir_or_data\n",
    "#     model_state, optimizer_state = torch.load(os.path.join(\n",
    "#         best_checkpoint_dir, \"checkpoint\"))\n",
    "#     best_trained_model.load_state_dict(model_state)\n",
    "\n",
    "    test_acc = test_accuracy(best_trained_model, device)\n",
    "    print(\"Best trial test set accuracy: {}\".format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the interval for model_2 is in this function\n",
    "def main_2(num_samples=10, max_num_epochs=10, gpus_per_trial=2):\n",
    "    configs = {\n",
    "#         \"l1\": tune.sample_from(lambda _: 2 ** np.random.randint(8, 10)),\n",
    "        \"l1\": 256,\n",
    "        \"lr\": tune.loguniform(0.00883, 0.00885),\n",
    "#         \"lr\": 0.00105,\n",
    "#         \"batch_size\": tune.choice([16, 32]),\n",
    "        \"batch_size\": 16,\n",
    "        \"momentum\": tune.loguniform(0.65, 0.68)\n",
    "#         \"momentum\": 0.7\n",
    "    }\n",
    "    scheduler = ASHAScheduler(\n",
    "        metric=\"loss\",\n",
    "        mode=\"min\",\n",
    "        max_t=max_num_epochs,\n",
    "        grace_period=1,\n",
    "        reduction_factor=2)\n",
    "    reporter = CLIReporter(\n",
    "        # parameter_columns=[\"l1\", \"l2\", \"lr\", \"batch_size\"],\n",
    "        metric_columns=[\"loss\", \"accuracy\", \"training_iteration\"])\n",
    "    result = tune.run(\n",
    "        train_cifar,\n",
    "        resources_per_trial={\"cpu\": 2, \"gpu\": gpus_per_trial},\n",
    "        config=configs,\n",
    "        num_samples=num_samples,\n",
    "        scheduler=scheduler)\n",
    "#         progress_reporter=reporter)\n",
    "\n",
    "    best_trial = result.get_best_trial(\"loss\", \"min\", \"last\")\n",
    "    print(\"Best trial config: {}\".format(best_trial.config))\n",
    "    print(\"Best trial final validation loss: {}\".format(\n",
    "        best_trial.last_result[\"loss\"]))\n",
    "    print(\"Best trial final validation accuracy: {}\".format(\n",
    "        best_trial.last_result[\"accuracy\"]))\n",
    "\n",
    "    best_trained_model = MyConvNet(best_trial.config[\"l1\"])\n",
    "    device = \"cpu\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda:0\"\n",
    "        if gpus_per_trial > 1:\n",
    "            best_trained_model = nn.DataParallel(best_trained_model)\n",
    "    best_trained_model.to(device)\n",
    "\n",
    "#     best_checkpoint_dir = best_trial.checkpoint.dir_or_data\n",
    "#     model_state, optimizer_state = torch.load(os.path.join(\n",
    "#         best_checkpoint_dir, \"checkpoint\"))\n",
    "#     best_trained_model.load_state_dict(model_state)\n",
    "\n",
    "    test_acc = test_accuracy(best_trained_model, device)\n",
    "    print(\"Best trial test set accuracy: {}\".format(test_acc))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the model\n",
    "\n",
    "After selecting suitable hyperparameters, it comes to training models. Whening training models, such functions like ploting the loss and accuracy curves could be added to test whether it is overfitting, as mentioned above."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. code for ploting loss and accuracy curves. It will plot the training loss and validation loss for each epoch when training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_and_visualize(model, learning_rate, monmentum):\n",
    "    epoch = 10\n",
    "\n",
    "    device = \"cpu\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda\"\n",
    "        if torch.cuda.device_count() > 1:\n",
    "            model = nn.DataParallel(model)\n",
    "    model.to(device)\n",
    "\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr = learning_rate, momentum=monmentum)\n",
    "\n",
    "    train_transform = transforms.Compose([transforms.RandomResizedCrop(224),\n",
    "                                          transforms.RandomHorizontalFlip(),\n",
    "                                          transforms.ToTensor(),\n",
    "                                          transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "                                         ])\n",
    "\n",
    "    csv_dir = \"/kaggle/input/deep-learning-for-msc-2022-23/train.csv\"\n",
    "    data_transform = train_transform\n",
    "    train_dir = \"/kaggle/input/deep-learning-for-msc-2022-23/train\"\n",
    "    trainset = CellPictureDataset(train_dir, csv_file=csv_dir, transform=data_transform)\n",
    "\n",
    "    test_abs = int(len(trainset) * 0.8)\n",
    "    train_subset, val_subset = random_split(\n",
    "        trainset, [test_abs, len(trainset) - test_abs])\n",
    "\n",
    "    trainloader =DataLoader(\n",
    "        train_subset,\n",
    "        batch_size=int(16),\n",
    "        shuffle=True,\n",
    "        num_workers=0)\n",
    "    valloader = DataLoader(\n",
    "        val_subset,\n",
    "        batch_size=int(16),\n",
    "        shuffle=True,\n",
    "        num_workers=0)\n",
    "    train_losses = []\n",
    "    train_accs = []\n",
    "    val_losses = []\n",
    "    val_accs = []\n",
    "\n",
    "    for epoch in range(epoch):\n",
    "        # train the model\n",
    "        train_loss = 0.0\n",
    "        train_acc = 0.0\n",
    "        # total_train = 0\n",
    "        # step_train = 0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            # ...\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.cpu().detach().numpy()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            # total_train += labels.size(0)\n",
    "            train_acc += (predicted == labels).sum().item() / len(labels)\n",
    "\n",
    "        train_loss /= len(trainloader)\n",
    "        train_acc /= len(trainloader)\n",
    "        train_losses.append(train_loss)\n",
    "        train_accs.append(train_acc)\n",
    "\n",
    "        # validate the model\n",
    "        val_loss = 0.0\n",
    "        val_acc = 0.0\n",
    "        # total = 0\n",
    "        # correct = 0\n",
    "        val_steps = 0\n",
    "        with torch.no_grad():\n",
    "            for i, data in enumerate(valloader, 0):\n",
    "                with torch.no_grad():\n",
    "                    inputs, labels = data\n",
    "                    inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                    outputs = model(inputs)\n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "                    # total += labels.size(0)\n",
    "                    # correct += (predicted == labels).sum().item()\n",
    "\n",
    "                    loss = loss_fn(outputs, labels)\n",
    "                    val_loss += loss.cpu().numpy()\n",
    "                    # val_loss += loss.item()\n",
    "                    val_acc += (predicted == labels).sum().item() / len(labels)\n",
    "\n",
    "        val_loss /= len(valloader)\n",
    "        val_acc /= len(valloader)\n",
    "        val_losses.append(val_loss)\n",
    "        val_accs.append(val_acc)\n",
    "\n",
    "    # create a figure with two subplots\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "    # plot the training and validation losses\n",
    "    axs[0].plot(train_losses, label=\"Training Loss\")\n",
    "    axs[0].plot(val_losses, label=\"Validation Loss\")\n",
    "    axs[0].legend()\n",
    "    axs[0].set_xlabel(\"Epoch\")\n",
    "    axs[0].set_ylabel(\"Loss\")\n",
    "\n",
    "    # plot the training and validation accuracies\n",
    "    axs[1].plot(train_accs, label=\"Training Accuracy\")\n",
    "    axs[1].plot(val_accs, label=\"Validation Accuracy\")\n",
    "    axs[1].legend()\n",
    "    axs[1].set_xlabel(\"Epoch\")\n",
    "    axs[1].set_ylabel(\"Accuracy\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Function for drawing confusion matrix. Confusion matrix is useful in machine learning and deep learning. It shows evaluaion standards beyond loss and accuracy, which is a good tool to analyse the model. In this part, a batch of dataset would be selected as an example to show the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "def cnf_matrix_plotter(model, cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    import trained model, labels and colored map\n",
    "    \"\"\"\n",
    "    train_transform = transforms.Compose([transforms.RandomResizedCrop(224),\n",
    "                                          transforms.RandomHorizontalFlip(),\n",
    "                                          transforms.ToTensor(),\n",
    "                                          transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "                                         ])\n",
    "    train_dataset = CellPictureDataset('/kaggle/input/deep-learning-for-msc-2022-23/train', csv_file='/kaggle/input/deep-learning-for-msc-2022-23/train.csv', transform=train_transform)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, num_workers=0)\n",
    "\n",
    "    images, labels = next(iter(train_loader))\n",
    "    outputs = model(images)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "    cm = confusion_matrix(labels.numpy(), predicted.numpy())\n",
    "    \n",
    "    plt.figure(figsize=(4, 4))\n",
    "    \n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    # plt.colorbar() \n",
    "    tick_marks = np.arange(len(classes))\n",
    "    \n",
    "    plt.title('confusion matrix', fontsize=30)\n",
    "    plt.xlabel('predicted', fontsize=25, c='r')\n",
    "    plt.ylabel('real class', fontsize=25, c='r')\n",
    "    plt.tick_params(labelsize=12) # set font size\n",
    "\n",
    "    # write numbers\n",
    "    threshold = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > threshold else \"black\",\n",
    "                 fontsize=12)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # plt.savefig('混淆矩阵.pdf', dpi=300) # save figures"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpertation for models\n",
    "\n",
    "After getting the models, we need to know how the models work, and analyse why the models generate such result. A necessary part is model interpretaion. In pytorch, the captum could be used for analysing how the model works. As an example, the occlusion and intergrated gradient are shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from captum.attr import IntegratedGradients\n",
    "from captum.attr import GradientShap\n",
    "from captum.attr import Occlusion\n",
    "from captum.attr import NoiseTunnel\n",
    "from captum.attr import visualization as viz\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Occlusion. Occlusion uses a block to cover a part of the picture to test whether this part contributes an important role for the predicted result. The size of block can be changed, when using a small block could not get a good result, it can be changed to a larger block. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doing_occulsion(model, img_pil):\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    transform_A = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),          \n",
    "        transforms.ToTensor()         \n",
    "    ])\n",
    "    transform_B = transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "    model.eval().to(device)\n",
    "    rc_img = transform_A(img_pil)\n",
    "    rc_img_norm = np.transpose(rc_img.squeeze().cpu().detach().numpy(), (1,2,0))\n",
    "    input_tensor = transform_B(rc_img).unsqueeze(0).to(device)\n",
    "    pred_logits = model(input_tensor)\n",
    "    pred_softmax = F.softmax(pred_logits, dim=1)\n",
    "    pred_conf, pred_id = torch.topk(pred_softmax, 1)\n",
    "    pred_conf = pred_conf.detach().cpu().numpy().squeeze().item()\n",
    "    pred_id = pred_id.detach().cpu().numpy().squeeze().item()\n",
    "    \n",
    "    occlusion = Occlusion(model)\n",
    "    attributions_occ = occlusion.attribute(input_tensor,\n",
    "                                       strides = (3, 8, 8), # 遮挡滑动移动步长\n",
    "                                       target=pred_id, # 目标类别\n",
    "                                       sliding_window_shapes=(3, 15, 15), # 遮挡滑块尺寸\n",
    "                                       baselines=0) # 被遮挡滑块覆盖的像素值\n",
    "    attributions_occ_norm = np.transpose(attributions_occ.detach().cpu().squeeze().numpy(), (1,2,0))\n",
    "    viz.visualize_image_attr_multiple(attributions_occ_norm, # 224 224 3\n",
    "                                  rc_img_norm,           # 224 224 3\n",
    "                                  [\"original_image\", \"heat_map\"],\n",
    "                                  [\"all\", \"positive\"],\n",
    "                                  show_colorbar=True,\n",
    "                                  outlier_perc=2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Intergrated gradients\n",
    "Intergrated gradients shows the process of a pixel from 0 to its original value in intergrated gradient. This can conclude the importance of each pixel for the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doing_ig(model, img_pil):\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    transform_A = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),          \n",
    "        transforms.ToTensor()         \n",
    "    ])\n",
    "    transform_B = transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "    model.eval().to(device)\n",
    "    rc_img = transform_A(img_pil)\n",
    "    rc_img_norm = np.transpose(rc_img.squeeze().cpu().detach().numpy(), (1,2,0))\n",
    "    input_tensor = transform_B(rc_img).unsqueeze(0).to(device)\n",
    "    pred_logits = model(input_tensor)\n",
    "    pred_softmax = F.softmax(pred_logits, dim=1)\n",
    "    pred_conf, pred_id = torch.topk(pred_softmax, 1)\n",
    "    pred_conf = pred_conf.detach().cpu().numpy().squeeze().item()\n",
    "    pred_id = pred_id.detach().cpu().numpy().squeeze().item()\n",
    "    \n",
    "    integrated_gradients = IntegratedGradients(model)\n",
    "    attributions_ig = integrated_gradients.attribute(input_tensor, target=pred_id, n_steps=200)\n",
    "    attributions_ig_norm = np.transpose(attributions_ig.detach().cpu().squeeze().numpy(), (1,2,0))\n",
    "    plt.imshow(attributions_ig_norm[:, :, 0] * 100)\n",
    "\n",
    "    default_cmap = LinearSegmentedColormap.from_list('custom blue', \n",
    "                                                 [(0, '#ffffff'),\n",
    "                                                  (0.25, '#000000'),\n",
    "                                                  (1, '#000000')], N=256)\n",
    "\n",
    "# 可视化 IG 值\n",
    "    viz.visualize_image_attr(attributions_ig_norm, # 224,224,3\n",
    "                            rc_img_norm,          # 224,224,3\n",
    "                            method='heat_map',\n",
    "                            cmap=default_cmap,\n",
    "                            show_colorbar=True,\n",
    "                            sign='positive',\n",
    "                            outlier_perc=1)\n",
    "    \n",
    "    # add noise to make the figure smooth\n",
    "    noise_tunnel = NoiseTunnel(integrated_gradients) \n",
    "\n",
    "    # 获得输入图像每个像素的 IG 值\n",
    "    attributions_ig_nt = noise_tunnel.attribute(input_tensor, nt_samples=2, nt_type='smoothgrad_sq', target=pred_id)\n",
    "\n",
    "    # 转为 224 x 224 x 3的数据维度\n",
    "    attributions_ig_nt_norm = np.transpose(attributions_ig_nt.squeeze().cpu().detach().numpy(), (1,2,0))\n",
    "\n",
    "    # 设置配色方案\n",
    "    default_cmap = LinearSegmentedColormap.from_list('custom blue', \n",
    "                                                    [(0, '#ffffff'),\n",
    "                                                    (0.25, '#000000'),\n",
    "                                                    (1, '#000000')], N=256)\n",
    "\n",
    "    viz.visualize_image_attr_multiple(attributions_ig_nt_norm, # 224 224 3\n",
    "                                    rc_img_norm, # 224 224 3\n",
    "                                    [\"original_image\", \"heat_map\"],\n",
    "                                    [\"all\", \"positive\"],\n",
    "                                    cmap=default_cmap,\n",
    "                                    show_colorbar=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other transition functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get and save model_1 to a lcoal .pth file\n",
    "def get_best_model1(lr, monmentum, l1):\n",
    "    # total_train_step = 0\n",
    "    # total_test_step = 0\n",
    "    model = MyConvNet(l1=l1)\n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda\"\n",
    "        if torch.cuda.device_count() > 1:\n",
    "            net = nn.DataParallel(net)\n",
    "    model.to(device)\n",
    "\n",
    "    csv_dir = \"D://python_code//deep learning coursework//train.csv\"\n",
    "    # data_transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize([0.5,0.5,0.5],[0.5,0.5,0.5])])\n",
    "    train_transform = transforms.Compose([transforms.RandomResizedCrop(224),\n",
    "                                      transforms.RandomHorizontalFlip(),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "                                     ])\n",
    "    train_dir = \"D://python_code//deep learning coursework//train\"\n",
    "    trainset = CellPictureDataset(train_dir, csv_file=csv_dir, transform=train_transform)\n",
    "    train_loader = DataLoader(trainset, batch_size=32, shuffle=True, num_workers=0)\n",
    "    \n",
    "    epoch = 35\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(lr=lr, momentum=monmentum)\n",
    "    for i in range(epoch):\n",
    "        # print(\"-------no.{} train begin\".format(i+1))\n",
    "        for data in train_loader:\n",
    "            image, label = data\n",
    "            image, label = image.to(device), label.to(device)\n",
    "            outputs = model(image)\n",
    "            loss = loss_fn(outputs, label)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    torch.save(model, 'myconvnet.pth')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get and save model_2 to a local .pth file\n",
    "def get_best_model2(lr, monmentum):\n",
    "\n",
    "    model = torchvision.models.resnet18()   \n",
    "    model.fc = nn.Linear(model.fc.in_features, 4)\n",
    "    device = \"cpu\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda\"\n",
    "        if torch.cuda.device_count() > 1:\n",
    "            net = nn.DataParallel(net)\n",
    "    model.to(device)\n",
    "    \n",
    "    csv_dir = \"D://python_code//deep learning coursework//train.csv\"\n",
    "    # data_transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize([0.5,0.5,0.5],[0.5,0.5,0.5])])\n",
    "    train_transform = transforms.Compose([transforms.RandomResizedCrop(224),\n",
    "                                      transforms.RandomHorizontalFlip(),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "                                     ])\n",
    "    train_dir = \"D://python_code//deep learning coursework//train\"\n",
    "    trainset = CellPictureDataset(train_dir, csv_file=csv_dir, transform=train_transform)\n",
    "    train_loader = DataLoader(trainset, batch_size=32, shuffle=True, num_workers=0)\n",
    "\n",
    "    epoch = 35\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=monmentum)\n",
    "    for i in range(epoch):\n",
    "        print(\"-------no.{} train begin\".format(i+1))\n",
    "        for data in train_loader:\n",
    "            image, label = data\n",
    "            image, label = image.to(device), label.to(device)\n",
    "            outputs = model(image)\n",
    "            loss = loss_fn(outputs, label)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    torch.save(model, 'resnet18.pth')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output the target .cvs result file\n",
    "def get_result(model):\n",
    "    test_transform = transforms.Compose([transforms.Resize(256),\n",
    "                                         transforms.CenterCrop(224),\n",
    "                                         transforms.ToTensor(),\n",
    "                                         transforms.Normalize(\n",
    "                                             mean=[0.485, 0.456, 0.406], \n",
    "                                             std=[0.229, 0.224, 0.225])\n",
    "                                        ])\n",
    "    testset = CellPictureDataset(\"test\",transform=test_transform, test=True)\n",
    "    testloader = DataLoader(testset, batch_size=32, shuffle=False, num_workers=0)\n",
    "    device = \"cpu\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda\"\n",
    "    model.eval().to(device)\n",
    "\n",
    "    labels = []\n",
    "    for data in testloader:\n",
    "            image = data.to(device)\n",
    "            outputs = model(image)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            label_list = list(predicted.cpu().numpy())\n",
    "            for label in label_list:\n",
    "                 labels.append(label)\n",
    "    data_frame = {'Filename': os.listdir('test'),\n",
    "                  'Label': labels\n",
    "                  }\n",
    "    df = pd.DataFrame(data_frame)\n",
    "    df.to_csv(\"example.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main_1(num_samples=10, max_num_epochs=35, gpus_per_trial=2)\n",
    "    main_2(num_samples=10, max_num_epochs=35, gpus_per_trial=2)\n",
    "    net_1 = get_best_model1(lr= 0.008830556690188944, monmentum= 0.6994160916279658)\n",
    "    net_2 = get_best_model2(lr= 0.0015, monmentum= 0.9784381166958563)\n",
    "    show_number()\n",
    "    show_a_batch()\n",
    "    training_and_visualize(MyConvNet(l1=256), lr=0.008830556690188944, momentum=0.6994160916279658)\n",
    "    cnf_matrix_plotter(net_1)\n",
    "    cnf_matrix_plotter(net_2)\n",
    "\n",
    "    # randomly select a picture from train dataset\n",
    "    img_path = \"/kaggle/input/deep-learning-for-msc-2022-23/train/7.png\"\n",
    "    img_pil = Image.open(img_path)\n",
    "    doing_occulsion(net_1, img_pil=img_pil)\n",
    "    doing_occulsion(net_2, img_pil=img_pil)\n",
    "    doing_ig(net_1, img_pil=img_pil)\n",
    "    doing_ig(net_2, img_pil=img_pil)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
